# RAG项目流程图解析

## 一、文件上传和向量化流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                    文件上传和向量化流程                          │
└─────────────────────────────────────────────────────────────────┘

步骤1: 读取文件
┌──────────────┐
│ file.txt     │  "王大瓜 1990年出生"
└──────┬───────┘
       │
       │ TikaDocumentReader.get()
       ▼
┌─────────────────────────────────────┐
│ List<Document> documents            │
│ ┌─────────────────────────────────┐ │
│ │ Document {                      │ │
│ │   content: "王大瓜 1990年出生"  │ │
│ │   metadata: {...}               │ │
│ │ }                               │ │
│ └─────────────────────────────────┘ │
└──────────────┬──────────────────────┘
               │
               │ tokenTextSplitter.apply()
               ▼
步骤2: 文本切分
┌─────────────────────────────────────┐
│ List<Document> documentSplitterList │
│ ┌─────────────────────────────────┐ │
│ │ Document {                      │ │
│ │   content: "王大瓜 1990年出生"  │ │
│ │   metadata: {...}               │ │
│ │ }                               │ │
│ └─────────────────────────────────┘ │
└──────────────┬──────────────────────┘
               │
               │ forEach(添加元数据)
               ▼
步骤3: 添加元数据
┌─────────────────────────────────────┐
│ List<Document> documentSplitterList │
│ ┌─────────────────────────────────┐ │
│ │ Document {                      │ │
│ │   content: "王大瓜 1990年出生"  │ │
│ │   metadata: {                   │ │
│ │     "knowledge": "知识库1"      │ │
│ │   }                             │ │
│ │ }                               │ │
│ └─────────────────────────────────┘ │
└──────────────┬──────────────────────┘
               │
               │ pgVectorStore.accept()
               ▼
步骤4: 向量化和存储
       ┌─────────────────┐
       │ 内部处理流程     │
       └────────┬────────┘
                │
    ┌───────────┴───────────┐
    │                       │
    ▼                       ▼
┌──────────────┐    ┌──────────────────┐
│ 向量化        │    │ 存储到PostgreSQL  │
│              │    │                  │
│ 文本:        │    │ INSERT INTO      │
│ "王大瓜..."  │    │ vector_store     │
│      ↓       │    │ VALUES (         │
│ 向量:        │    │   id,            │
│ [0.123,      │    │   content,       │
│  -0.456,     │    │   embedding,    │
│  0.789,      │    │   metadata      │
│  ...]        │    │ )               │
└──────────────┘    └──────────────────┘
    │                       │
    └───────────┬───────────┘
                │
                ▼
        ┌───────────────┐
        │ 存储完成！     │
        │ 向量已存入数据库│
        └───────────────┘
```

---

## 二、对话查询流程图

```
┌─────────────────────────────────────────────────────────────────┐
│                        对话查询流程                               │
└─────────────────────────────────────────────────────────────────┘

步骤1: 用户提问
┌──────────────────────┐
│ 用户问题:            │
│ "王大瓜，哪年出生？" │
└──────────┬───────────┘
           │
           │ SearchRequest.query()
           ▼
步骤2: 构建搜索请求
┌─────────────────────────────────────┐
│ SearchRequest {                     │
│   query: "王大瓜，哪年出生"         │
│   topK: 5                           │
│   filterExpression:                │
│     "knowledge == '知识库1'"        │
│ }                                   │
└──────────┬──────────────────────────┘
           │
           │ pgVectorStore.similaritySearch()
           ▼
步骤3: 向量相似度搜索
       ┌─────────────────┐
       │ 内部处理流程     │
       └────────┬────────┘
                │
    ┌───────────┴───────────┐
    │                       │
    ▼                       ▼
┌──────────────┐    ┌──────────────────┐
│ 问题向量化    │    │ 数据库向量搜索   │
│              │    │                  │
│ "王大瓜..."  │    │ SELECT * FROM    │
│      ↓       │    │ vector_store     │
│ [0.234,      │    │ WHERE            │
│  -0.567,     │    │   embedding <->  │
│  0.890,      │    │   query_vector   │
│  ...]        │    │ ORDER BY distance│
└──────────────┘    │ LIMIT 5          │
    │               └──────────────────┘
    │                       │
    └───────────┬───────────┘
                │
                ▼
步骤4: 检索结果
┌─────────────────────────────────────┐
│ List<Document> documents            │
│ ┌─────────────────────────────────┐ │
│ │ Document {                      │ │
│ │   content: "王大瓜 1990年出生"  │ │
│ │   metadata: {"knowledge": "知识库1"}│
│ │ }                               │ │
│ └─────────────────────────────────┘ │
└──────────┬───────────────────────────┘
           │
           │ stream().map().collect()
           ▼
步骤5: 合并文档内容
┌──────────────────────┐
│ String documentsCollectors│
│ "王大瓜 1990年出生"  │
└──────────┬───────────┘
           │
           │ SystemPromptTemplate.createMessage()
           ▼
步骤6: 构建系统提示词
┌─────────────────────────────────────┐
│ SystemMessage {                     │
│   content: """                      │
│     Use the information from        │
│     DOCUMENTS section...            │
│     DOCUMENTS:                      │
│       王大瓜 1990年出生             │
│     """                             │
│ }                                   │
└──────────┬──────────────────────────┘
           │
           │ 构建消息列表
           ▼
步骤7: 构建消息列表
┌─────────────────────────────────────┐
│ List<Message> messages               │
│ ┌─────────────────────────────────┐ │
│ │ UserMessage {                    │ │
│ │   "王大瓜，哪年出生？"           │ │
│ │ }                               │ │
│ └─────────────────────────────────┘ │
│ ┌─────────────────────────────────┐ │
│ │ SystemMessage {                 │ │
│ │   "Use DOCUMENTS...\n            │ │
│ │    DOCUMENTS:\n                  │ │
│ │    王大瓜 1990年出生"           │ │
│ │ }                               │ │
│ └─────────────────────────────────┘ │
└──────────┬───────────────────────────┘
           │
           │ ollamaChatClient.call()
           ▼
步骤8: 调用LLM生成回答
       ┌─────────────────┐
       │ Ollama服务       │
       │ (deepseek-r1:1.5b)│
       └────────┬────────┘
                │
                ▼
       ┌─────────────────┐
       │ 模型推理过程     │
       │                 │
       │ 输入:           │
       │ - 系统提示词    │
       │ - 用户问题      │
       │ - 检索到的文档  │
       │                 │
       │ 处理:           │
       │ - 理解问题      │
       │ - 提取文档信息  │
       │ - 生成回答      │
       │                 │
       │ 输出:           │
       │ "王大瓜出生于   │
       │  1990年。"      │
       └────────┬────────┘
                │
                ▼
步骤9: 返回结果
┌─────────────────────────────────────┐
│ ChatResponse {                      │
│   result: {                         │
│     output: {                       │
│       content: "王大瓜出生于1990年。"│
│     }                               │
│   }                                 │
│ }                                   │
└─────────────────────────────────────┘
```

---

## 三、数据流转图

```
┌──────────────────────────────────────────────────────────────┐
│                      数据流转过程                              │
└──────────────────────────────────────────────────────────────┘

【上传阶段】
文件文本
  │
  ├─→ Document (原始)
  │     │
  │     ├─→ content: "王大瓜 1990年出生"
  │     └─→ metadata: {}
  │
  ├─→ Document (切分后)
  │     │
  │     ├─→ content: "王大瓜 1990年出生"
  │     └─→ metadata: {"knowledge": "知识库1"}
  │
  └─→ 向量化
        │
        ├─→ embedding: [0.123, -0.456, 0.789, ...]
        └─→ 存储到PostgreSQL
              │
              └─→ 数据库记录
                    ├─→ id: "doc-id-1"
                    ├─→ content: "王大瓜 1990年出生"
                    ├─→ embedding: [0.123, -0.456, ...]
                    └─→ metadata: {"knowledge": "知识库1"}


【查询阶段】
用户问题
  │
  ├─→ "王大瓜，哪年出生？"
  │
  ├─→ 向量化
  │     │
  │     └─→ query_vector: [0.234, -0.567, 0.890, ...]
  │
  ├─→ 相似度搜索
  │     │
  │     └─→ 找到最相似的文档
  │           │
  │           └─→ Document {
  │                 content: "王大瓜 1990年出生"
  │               }
  │
  ├─→ 合并文档
  │     │
  │     └─→ "王大瓜 1990年出生"
  │
  ├─→ 构建提示词
  │     │
  │     └─→ SystemMessage {
  │           "Use DOCUMENTS...\nDOCUMENTS:\n王大瓜 1990年出生"
  │         }
  │
  └─→ LLM生成
        │
        └─→ "王大瓜出生于1990年。"
```

---

## 四、关键函数输入输出对照表

### 上传流程函数

| 函数 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `TikaDocumentReader.get()` | 文件路径 | `List<Document>` | 读取文件，返回Document列表 |
| `tokenTextSplitter.apply()` | `List<Document>` | `List<Document>` | 切分文本，返回切分后的Document列表 |
| `doc.getMetadata().put()` | Document, key, value | void | 修改Document的元数据（无返回值） |
| `pgVectorStore.accept()` | `List<Document>` | void | 向量化并存储到数据库（无返回值） |

### 查询流程函数

| 函数 | 输入 | 输出 | 说明 |
|------|------|------|------|
| `SearchRequest.query()` | String (查询文本) | `SearchRequest` | 创建搜索请求对象 |
| `request.withTopK()` | int (数量) | `SearchRequest` | 设置返回结果数量 |
| `request.withFilterExpression()` | String (过滤表达式) | `SearchRequest` | 设置过滤条件 |
| `pgVectorStore.similaritySearch()` | `SearchRequest` | `List<Document>` | 执行向量搜索，返回相关文档 |
| `documents.stream().map().collect()` | `List<Document>` | `String` | 提取并合并文档内容 |
| `SystemPromptTemplate.createMessage()` | `String` (模板), `Map` (参数) | `Message` | 创建系统提示词消息 |
| `ollamaChatClient.call()` | `Prompt` | `ChatResponse` | 调用LLM生成回答 |

---

## 五、向量相似度搜索原理图

```
┌──────────────────────────────────────────────────────────────┐
│              向量相似度搜索原理                                 │
└──────────────────────────────────────────────────────────────┘

数据库中的向量:
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│ 文档1向量    │  │ 文档2向量    │  │ 文档3向量    │
│ [0.1, 0.2,  │  │ [0.5, 0.6,  │  │ [0.8, 0.9,  │
│  0.3, ...]  │  │  0.7, ...]  │  │  1.0, ...]  │
└─────────────┘  └─────────────┘  └─────────────┘
     │                 │                 │
     │                 │                 │
     └─────────────────┴─────────────────┘
                       │
                       │ 计算距离
                       │
         ┌─────────────▼─────────────┐
         │   查询向量                │
         │   [0.12, 0.25, 0.35, ...] │
         └─────────────┬─────────────┘
                       │
         ┌─────────────┴─────────────┐
         │                            │
    ┌────▼────┐                  ┌────▼────┐
    │ 距离计算 │                  │ 排序筛选 │
    │         │                  │         │
    │ 文档1:  │                  │ 文档1:  │
    │ 距离=0.1│                  │ 距离=0.1│ ← 最相似
    │         │                  │         │
    │ 文档2:  │                  │ 文档3:  │
    │ 距离=0.8│                  │ 距离=0.9│
    │         │                  │         │
    │ 文档3:  │                  │ 文档2:  │
    │ 距离=0.9│                  │ 距离=0.8│
    └─────────┘                  └─────────┘
         │                            │
         └─────────────┬───────────────┘
                       │
                       ▼
             返回前K个最相似的文档
```

---

## 六、RAG完整架构图

```
┌──────────────────────────────────────────────────────────────┐
│                      RAG系统架构                               │
└──────────────────────────────────────────────────────────────┘

                    ┌──────────────┐
                    │   用户界面    │
                    │  (前端/API)  │
                    └──────┬───────┘
                           │
                           │ HTTP请求
                           ▼
            ┌──────────────────────────────┐
            │    Spring Boot 应用          │
            │                              │
            │  ┌────────────────────────┐  │
            │  │  OllamaController      │  │
            │  │  (HTTP接口层)          │  │
            │  └───────────┬────────────┘  │
            │              │                │
            │  ┌───────────▼────────────┐  │
            │  │  RAGTest / Service     │  │
            │  │  (业务逻辑层)           │  │
            │  └───────────┬────────────┘  │
            │              │                │
            │  ┌───────────▼────────────┐  │
            │  │  Spring AI 组件        │  │
            │  │  - TikaDocumentReader  │  │
            │  │  - TokenTextSplitter   │  │
            │  │  - PgVectorStore       │  │
            │  │  - OllamaChatClient    │  │
            │  └───────────┬────────────┘  │
            └──────────────┼───────────────┘
                           │
        ┌──────────────────┼──────────────────┐
        │                  │                  │
        ▼                  ▼                  ▼
┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│   Ollama     │  │  PostgreSQL  │  │    Redis     │
│  服务        │  │  + pgvector  │  │   (缓存)     │
│              │  │              │  │              │
│ - LLM模型    │  │ - 向量存储    │  │ - 会话缓存   │
│ - Embedding  │  │ - 文本内容    │  │ - 数据缓存   │
│   模型       │  │ - 元数据      │  │              │
└──────────────┘  └──────────────┘  └──────────────┘
```

---

## 七、关键数据对象结构

### Document对象
```java
Document {
    String id;                    // 唯一标识符
    String content;               // 文本内容
    Map<String, Object> metadata; // 元数据
    // 内部还包含:
    // - embedding: float[]       // 向量（可选）
    // - distance: double         // 相似度距离（搜索时）
}
```

### SearchRequest对象
```java
SearchRequest {
    String query;                 // 查询文本
    int topK;                     // 返回结果数量
    String filterExpression;      // 过滤表达式
    // 其他可选参数:
    // - similarityThreshold: double  // 相似度阈值
    // - distanceType: String        // 距离类型
}
```

### ChatResponse对象
```java
ChatResponse {
    ChatResult result {
        AssistantMessage output {
            String content;       // LLM生成的回答
        }
    }
    Map<String, Object> metadata;  // 元数据（token使用量等）
}
```

---

## 八、执行时序图

```
用户          Controller        Service          VectorStore      Ollama        PostgreSQL
 │              │                 │                 │              │              │
 │──上传文件───>│                 │                 │              │              │
 │              │──读取文件──────>│                 │              │              │
 │              │                 │──TikaReader───>│              │              │
 │              │                 │<──Document─────│              │              │
 │              │                 │──切分文本──────>│              │              │
 │              │                 │<──Document[]───│              │              │
 │              │                 │──向量化───────>│              │              │
 │              │                 │                 │──embed()───>│              │
 │              │                 │                 │<──vector────│              │
 │              │                 │──存储─────────>│              │              │
 │              │                 │                 │──────────────┼─────────────>│
 │              │                 │                 │              │              │
 │              │<──完成──────────│                 │              │              │
 │<──成功───────│                 │                 │              │              │
 │              │                 │                 │              │              │
 │──提问───────>│                 │                 │              │              │
 │              │──搜索──────────>│                 │              │              │
 │              │                 │──相似度搜索───>│              │              │
 │              │                 │                 │──embed()───>│              │
 │              │                 │                 │<──vector────│              │
 │              │                 │                 │──────────────┼─────────────>│
 │              │                 │                 │<──Document[]─┼──────────────│
 │              │                 │<──Document[]───│              │              │
 │              │                 │──生成提示词───>│              │              │
 │              │                 │──调用LLM──────>│              │              │
 │              │                 │                 │──call()─────>│              │
 │              │                 │                 │              │──推理───────>│
 │              │                 │                 │              │<──回答───────│
 │              │                 │                 │<──Response───│              │
 │              │<──ChatResponse──│                 │              │              │
 │<──回答───────│                 │                 │              │              │
```

---

## 总结

这个流程图展示了RAG系统的完整工作流程：

1. **上传阶段**: 文件 → 读取 → 切分 → 向量化 → 存储
2. **查询阶段**: 问题 → 向量化 → 搜索 → 检索 → 提示词 → LLM → 回答

每个步骤都有明确的输入输出，通过Spring AI框架的封装，简化了复杂的向量操作。

